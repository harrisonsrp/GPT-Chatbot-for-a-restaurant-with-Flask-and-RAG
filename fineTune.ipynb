{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General libraries\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "\n",
    "#Fine tune libs\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "#infrence lib\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting json to txt\n",
    "prompt_json = r\"C:\\Projects\\GPTChatbot_rag\\Prompt_data\\prompt_dataset.json\"\n",
    "with open(prompt_json, 'r') as prompts:\n",
    "    df = json.load(prompts)\n",
    "    \n",
    "prompt_txt = []\n",
    "for conversations in df:\n",
    "    # f\"{conversations['user']}\\n{conversations['bot']}\\n\\n\n",
    "    # print(conversations['user'])\n",
    "    user = conversations['user']\n",
    "    bot = conversations['bot']\n",
    "    prompt_txt.append(user)\n",
    "    prompt_txt.append(bot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts are written to txt file successfully!\n"
     ]
    }
   ],
   "source": [
    "prompt_txt_file = r\"C:\\Projects\\GPTChatbot_rag\\Prompt_data\\prompt_txt.txt\"\n",
    "with open(prompt_txt_file, 'w') as prompt_txt_file:\n",
    "    for line in prompt_txt:\n",
    "        try:\n",
    "            prompt_txt_file.write(line)\n",
    "            prompt_txt_file.write('\\n')\n",
    "        except:\n",
    "            pass\n",
    "print(\"Prompts are written to txt file successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n",
      "Hi!\n",
      "Hello\n",
      "Hello!\n",
      "Hey there\n",
      "Hi\n",
      "Good morning\n",
      "Hi\n",
      "Hi\n",
      "Hi\n",
      "Good afternoon\n",
      "Hi\n",
      "Greetings\n",
      "Hi\n",
      "Yo\n",
      "Hi\n",
      "Hey\n",
      "Hi\n",
      "Hi there\n",
      "Hi\n",
      "Hello there\n",
      "Hi\n",
      "Hiya\n",
      "Hi\n",
      "Good day\n",
      "Hi\n",
      "Hey!\n",
      "Hi\n",
      "Hi!\n",
      "Hi\n",
      "Hey there!\n",
      "Hi\n",
      "Good morning!\n",
      "Hi\n",
      "Hey!\n",
      "Hi\n",
      "Good evening!\n",
      "Hi\n",
      "Hi!\n",
      "Hi\n",
      "Hello there!\n",
      "Hi\n",
      "Good day!\n",
      "Hi\n",
      "How's it going!\n",
      "Hi\n",
      "Hey!\n",
      "Hi\n",
      "Hi!\n",
      "Hi\n",
      "Hello!\n",
      "Hi\n",
      "Hey there!\n",
      "Hi\n",
      "Good morning!\n",
      "Hi\n",
      "Howdy!\n",
      "Hi\n",
      "Greetings!\n",
      "Hi\n",
      "Yo!\n",
      "Hi\n",
      "What is your address?\n",
      "Our address is\n",
      "Address?\n",
      "Our address is\n",
      "and your address?\n",
      "Our address is\n",
      "give me your address\n",
      "Our address is\n",
      "what is your location\n",
      "Our address is\n",
      "your telephone?\n",
      "Our address is\n",
      "what is your number\n",
      "Our address is\n",
      "What food do you have today?\n",
      "Today we have\n",
      "Do you have any vegetarian options?\n",
      "Yes, we have vegetarian foods that are\n",
      "Are there any gluten-free options available?\n",
      "Yes, we offer gluten-free food that are\n",
      "Can I see the dessert menu?\n",
      "Sure, our dessert options include\n",
      "Do you offer any beverages?\n",
      "Yes, we have a variety of drinks including\n",
      "any beverages?\n",
      "Yes, we have a variety of drinks including\n",
      "What drinks do you have?\n",
      "We have a variety of drinks including\n",
      "Do you offer any beverages?\n",
      "Yes, we have a variety of drinks including\n",
      "Do you have outdoor seating?\n",
      "Yes, we have.\n",
      "Is there a kids menu?\n",
      "Yes, we have kinds menu.\n",
      "What are your opening hours?\n",
      "The opening hour is\n",
      "When are you open?\n",
      "The opening hour is\n",
      "When restaurant is open?\n",
      "The opening hour is\n",
      "When can I come?\n",
      "The opening hour is\n",
      "Do you have any daily specials?\n",
      "Yes, today we have\n",
      "Are there any vegan options available?\n",
      "Yes, we offer vegan menu.\n",
      "vegan options available?\n",
      "Yes, we offer vegan menu.\n",
      "any vegan options?\n",
      "Yes, we offer vegan menu.\n",
      "do you any vegan food?\n",
      "Yes, we offer vegan menu.\n",
      "Can I make a reservation for a large group?\n",
      "Yes, we accept reservations.\n",
      "I want to reserve a table\n",
      "You can reserve a table online.\n",
      "Do you have any table?\n",
      "Currently \n",
      "Can I reserve a table online?\n",
      "Yes.\n",
      "Can I reserve a table?\n",
      "Yes you can.\n",
      "Can I reserve a seat?\n",
      "Yes you can.\n",
      "I wanna reserve a table\n",
      "Yes you can.\n",
      "Do you have empty seat?\n",
      "Yes.\n",
      "Do you have any desserts?\n",
      "Sure, our dessert options include\n",
      "Are there any nut-free options available?\n",
      "Yes, we have nut-free options.\n",
      "Can I see the drinks list?\n",
      "Yes, here it is.\n",
      "What kind of desserts do you have?\n",
      "We have garlic bread, mozzarella sticks, chicken wings, and bruschetta.\n",
      "Are there any vegetarian available?\n",
      "Yes, we offer seafood dishes.\n",
      "What types of food do you offer?\n",
      "We offer\n",
      "Do you have vegetarian foods?\n",
      "Yes, we offer several vegetarian foods including\n",
      "any vegetarian foods?\n",
      "Yes, we offer several vegetarian foods including\n",
      "Do you have vegetarian menu?\n",
      "Yes, we offer several vegetarian foods including.\n",
      "anything for vegetarians?\n",
      "Yes, we offer several vegetarian foods including.\n",
      "Are there any low-calorie options available?\n",
      "Yes, on our menu.\n",
      "Can I substitute ingredients in a dish?\n",
      "Yes, in many dishes.\n",
      "What kind of drinks do you have?\n",
      "We have\n",
      "Can I see the full menu?\n",
      "Of cource, Our full menu is\n",
      "Do you offer gift cards?\n",
      "Yes, in-store or online.\n",
      "Can I make a special request for my order?\n",
      "Yes, we'll accommodate.\n",
      "Are there any spicy dishes available?\n",
      "Yes, like buffalo chicken pizza.\n",
      "Do you offer gluten-free beer?\n",
      "Yes, as an option.\n",
      "Can I order dessert to go?\n",
      "Yes, for takeout.\n",
      "Do you have any happy hour specials?\n",
      "Yes, on select days.\n",
      "Is there a dress code?\n",
      "No strict code.\n",
      "Do you offer brunch on weekends?\n",
      "Yes, with breakfast and lunch options.\n",
      "Can I bring my own birthday cake?\n",
      "Yes, you can.\n",
      "Can I order a gluten-free pizza for delivery?\n",
      "Yes, specify dietary preferences.\n",
      "Do you have any outdoor seating?\n",
      "Yes, available.\n",
      "Can I order a special cake for a celebration?\n",
      "Yes, with advance notice.\n",
      "Are there any drinks available?\n",
      "Yes, drinks are available.\n",
      "Can I request extra sauce or toppings on my pizza?\n",
      "Yes, with extra charge.\n",
      "Do you offer live music or entertainment?\n",
      "Yes, occasionally.\n",
      "Are there any outdoor games or activities?\n",
      "Yes, weather permitting.\n",
      "Can I order food for pickup?\n",
      "Yes, by phone or online.\n",
      "Are there any lunch combos available?\n",
      "Yes, on weekdays.\n",
      "Can I request a private dining area for a special event?\n",
      "Yes, available.\n",
      "Do you offer any special discounts for seniors?\n",
      "Yes, on select items.\n",
      "Can I order a special cocktail?\n",
      "Yes, based on preference.\n",
      "Are there any spicy dishes on the menu?\n",
      "Yes, like jalapeno pop\n",
      "Do you offer gluten-free beer?\n",
      "Yes, as an alternative option.\n",
      "Can I order dessert to go?\n",
      "Yes, for takeout.\n",
      "Do you have any happy hour specials?\n",
      "Yes, on select days.\n",
      "Do you offer brunch on weekends?\n",
      "Yes, with breakfast and lunch options.\n",
      "Can I bring my own birthday cake?\n",
      "Yes, you can.\n",
      "Are there any seats available?\n",
      "Yes.\n",
      "Do you have any outdoor seating?\n",
      "Yes, available.\n",
      "Can I order a special cake for a celebration?\n",
      "Yes, with advance notice.\n",
      "Are there any kid-friendly drinks available?\n",
      "Yes, such as fruit juices.\n",
      "Can I request extra sauce or toppings on my pizza?\n",
      "Yes, with extra charge.\n",
      "Do you offer live music or entertainment?\n",
      "Yes, occasionally.\n",
      "Are there any outdoor games or activities?\n",
      "Yes, weather permitting.\n",
      "Can I order food for pickup?\n",
      "Yes, you can.\n",
      "Are there any lunch combos available?\n",
      "Yes, on weekdays.\n",
      "Can I request a private dining area for a special event?\n",
      "Yes, available.\n",
      "Do you offer any special discounts for seniors?\n",
      "Yes, on select items.\n",
      "Can I order a special cocktail?\n",
      "Yes, based on preference.\n",
      "Are there any spicy dishes on the menu?\n",
      "Yes, like jalapeno poppers.\n",
      "Do you have a wine list?\n",
      "Yes, with red, white, and sparkling wines.\n",
      "Are there any hidden charges on the bill?\n",
      "No hidden charges.\n",
      "Can I bring my own bottle of wine?\n",
      "Yes, with a corkage fee.\n",
      "Do you offer live music?\n",
      "Yes, on weekends.\n",
      "Is there a children's menu?\n",
      "Yes, with options like chicken tenders and macaroni.\n",
      "Do you offer any vegetarian appetizers?\n",
      "Yes, such as stuffed mushrooms and bruschetta.\n",
      "Are there any local beers on tap?\n",
      "Yes, local craft beers.\n",
      "Can I order a salad as a main course?\n",
      "Yes, with protein options.\n",
      "Do you have any signature cocktails?\n",
      "Yes, including our house margarita and mojito.\n",
      "Can I make a reservation for outdoor seating?\n",
      "Yes, specify when booking.\n",
      "Are there any age restrictions for the kids menu?\n",
      "Designed for children 12 and under.\n",
      "Can I order a side of bread with my meal?\n",
      "Yes, options like garlic bread.\n",
      "Is there a minimum order requirement for delivery?\n",
      "Yes, $20 minimum.\n",
      "Do you offer any breakfast specials?\n",
      "Yes, until 11:00 AM on weekends.\n",
      "Can I order extra sauce on the side?\n",
      "Yes, for an additional charge.\n",
      "Do you have any signature desserts?\n",
      "Yes, including\n",
      "how to contact you?\n",
      "To contact us, \n",
      "how to contact restaurant?\n",
      "To contact us, \n",
      "give me restaurant contact information\n",
      "To contact us, \n",
      "Are there any low-carb options on the menu?\n",
      "Yes, including salads and vegetable sides.\n",
      "Can I order a half-size portion of pasta?\n",
      "Yes, upon request.\n",
      "Are there any vegetarian entrees?\n",
      "Yes, we have.\n",
      "Do you offer any gluten-free pizza options?\n",
      "Yes, with gluten-free crust and toppings.\n",
      "Can I request a special table for a romantic dinner?\n",
      "Yes, please specify your preferences.\n",
      "Do you have any specials for seniors?\n",
      "Yes, on certain days.\n",
      "Can I order a side of soup with my sandwich?\n",
      "Yes, for an additional charge.\n",
      "Do you offer any non-alcoholic beverages?\n",
      "Yes, we do.\n",
      "Can I order a salad without the dressing?\n",
      "Yes, just let your server know.\n",
      "Are there any specials for military personnel?\n",
      "Yes, with valid ID.\n",
      "Can I order a side of fruit instead of fries?\n",
      "Yes, on select items.\n",
      "Do you offer any heart-healthy options?\n",
      "Yes, including grilled fish and salads.\n",
      "Are there any options for vegetarians?\n",
      "Yes, including veggie burgers and salads.\n",
      "Do you offer any locally sourced ingredients?\n",
      "Yes, whenever possible.\n",
      "Do you offer any lunch combos?\n",
      "Yes, with various choices.\n",
      "Can I order a side of bacon with my breakfast?\n",
      "Yes, for an additional charge.\n",
      "Are there any options for vegans?\n",
      "Yes, including .\n",
      "Can I order a side of salsa with my chips?\n",
      "Yes, for an additional charge.\n",
      "Do you offer any specials for birthdays?\n",
      "Yes, including free desserts.\n",
      "do you have desserts?\n",
      "Yes, we have desserts including\n",
      "what desserts do you have?\n",
      "We offer\n",
      "what desserts do you have?\n",
      "We have\n",
      "Do you offer any lunch specials?\n",
      "Yes we do.\n",
      "Goodbye\n",
      "Goodbye! Have a great day!\n",
      "See you later\n",
      "See you later! Take care!\n",
      "Bye\n",
      "Bye! Until next time!\n",
      "Take care\n",
      "You too! Take care!\n",
      "Farewell\n",
      "Farewell! Wishing you all the best!\n",
      "Have a good one\n",
      "You too! Have a good one!\n",
      "See you soon\n",
      "See you soon! Looking forward to it!\n",
      "So long\n",
      "So long! Until we meet again!\n",
      "Take it easy\n",
      "You too! Take it easy!\n",
      "Adios\n",
      "Adios! Hasta luego!\n",
      "Catch you later\n",
      "Catch you later! Bye for now!\n",
      "Later\n",
      "Later! Take care!\n",
      "Bye-bye\n",
      "Bye-bye! Until next time!\n",
      "See you\n",
      "See you! Take care!\n",
      "Until next time\n",
      "Until next time! Farewell!\n",
      "Goodnight\n",
      "Goodnight! Sweet dreams!\n",
      "Time to go\n",
      "Time to go! Take care!\n",
      "Bye now\n",
      "Bye now! Have a great day!\n",
      "Peace out\n",
      "Peace out! See you later!\n",
      "Cheerio\n",
      "Cheerio! Until we meet again!\n",
      "Take care of yourself\n",
      "You too! Take care of yourself!\n",
      "So long for now\n",
      "So long for now! See you soon!\n",
      "Bye for now\n",
      "Bye for now! Take care!\n",
      "Have a good day\n",
      "Thank you! You too! Have a good day!\n",
      "Can you tell me about your menu?\n",
      "We offer \n",
      "What's typically on your menu?\n",
      "We offer \n",
      "What kind of cuisine do you serve?\n",
      "We offer \n",
      "Tell me about the food options\n",
      "We offer \n",
      "What dishes do you have?\n",
      "We have \n",
      "What foods do you have?\n",
      "We have \n",
      "What do you have?\n",
      "We have \n",
      "What do you offer?\n",
      "We offer \n",
      "What do you offer today?\n",
      "We offer \n",
      "Do you have any offer?\n",
      "We offer \n",
      "Tell me about your menu\n",
      "We have \n",
      "What's available to eat?\n",
      "We have \n",
      "What's available to eat?\n",
      "We have \n",
      "Could you describe your menu?\n",
      "We have \n",
      "What's your menu like?\n",
      "We have \n",
      "what is your menu\n",
      "We have \n",
      "special offers today?\n",
      "We have \n",
      "What foods are on discount?\n",
      "We have \n",
      "What is the food of the day?\n",
      "We have\n"
     ]
    }
   ],
   "source": [
    "def read_documents_from_directory(directory):\n",
    "    combined_text = \"\"\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(file_path, \"r\") as file:\n",
    "                text = file.read()\n",
    "                combined_text += text\n",
    "    return combined_text\n",
    "\n",
    "# Read documents from the directory\n",
    "train_directory = r'C:\\Projects\\GPTChatbot_rag\\Prompt_data'\n",
    "text_data = read_documents_from_directory(train_directory)\n",
    "text_data = re.sub(r'\\n+', '\\n', text_data).strip()  # Remove excess newline characters\n",
    "\n",
    "print(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data created successfully!\n"
     ]
    }
   ],
   "source": [
    "with open(r\"C:\\Projects\\GPTChatbot_rag\\Prompt_data\\train.txt\", \"w\") as train_data:\n",
    "    train_data.write(text_data)\n",
    "print(\"Train data created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path, tokenizer, block_size = 128):\n",
    "    dataset = TextDataset(\n",
    "        tokenizer = tokenizer,\n",
    "        file_path = file_path,\n",
    "        block_size = block_size,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_collator(tokenizer, mlm = False):\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=mlm,\n",
    "    )\n",
    "    return data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_file_path,model_name,\n",
    "          output_dir,\n",
    "          overwrite_output_dir,\n",
    "          per_device_train_batch_size,\n",
    "          num_train_epochs,\n",
    "          save_steps):\n",
    "  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "  train_dataset = load_dataset(train_file_path, tokenizer)\n",
    "  data_collator = load_data_collator(tokenizer)\n",
    "\n",
    "  tokenizer.save_pretrained(output_dir)\n",
    "      \n",
    "  model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "  model.save_pretrained(output_dir)\n",
    "\n",
    "  training_args = TrainingArguments(\n",
    "          output_dir=output_dir,\n",
    "          overwrite_output_dir=overwrite_output_dir,\n",
    "          per_device_train_batch_size=per_device_train_batch_size,\n",
    "          num_train_epochs=num_train_epochs,\n",
    "      )\n",
    "\n",
    "  trainer = Trainer(\n",
    "          model=model,\n",
    "          args=training_args,\n",
    "          data_collator=data_collator,\n",
    "          train_dataset=train_dataset,\n",
    "  )\n",
    "      \n",
    "  trainer.train()\n",
    "  trainer.save_model()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = r\"C:\\Projects\\gptchatbot_rag\\prompt_data\\train.txt\"\n",
    "model_name = 'gpt2'\n",
    "output_dir = r'C:\\Projects\\gptchatbot_rag\\outputFineTune'\n",
    "overwrite_output_dir = True\n",
    "per_device_train_batch_size = 12\n",
    "num_train_epochs = 100\n",
    "save_steps = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hsohr\\miniconda3\\Lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "c:\\Users\\hsohr\\miniconda3\\Lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe272316b3142ca882cecfa9031ef53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1066.2269, 'train_samples_per_second': 1.97, 'train_steps_per_second': 0.188, 'train_loss': 0.37909980773925783, 'epoch': 100.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train(\n",
    "    train_file_path=train_file_path,\n",
    "    model_name=model_name,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=overwrite_output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    save_steps=save_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "    return model\n",
    "\n",
    "def load_tokenizer(tokenizer_path):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
    "    return tokenizer\n",
    "\n",
    "def generate_text(model_path, sequence, max_length):\n",
    "    model = load_model(model_path)\n",
    "    tokenizer = load_tokenizer(model_path)\n",
    "    \n",
    "    # Remove the user input from the sequence\n",
    "\n",
    "    \n",
    "    ids = tokenizer.encode(sequence, return_tensors='pt')\n",
    "    final_outputs = model.generate(\n",
    "        ids,\n",
    "        do_sample=True,\n",
    "        pad_token_id=model.config.eos_token_id,\n",
    "        top_k=100,\n",
    "        early_stopping=True,  \n",
    "        num_return_sequences=1,  \n",
    "        max_length=max_length,\n",
    "    )\n",
    "    generated_text = tokenizer.decode(final_outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Remove the bot prefix \"[bot]: \" from the generated text\n",
    "    # Define a regular expression pattern to match \"[bot]:\"\n",
    "    pattern = r'\\[bot\\]:'\n",
    "    # Replace the matched pattern with an empty string\n",
    "    generated_text = re.sub(pattern, '', generated_text)\n",
    "    generated_text = generated_text.split(\"\\n\")\n",
    "    generated_text = generated_text[1]\n",
    "    return generated_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello!'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_path = \"C:\\\\Projects\\\\gptchatbot_rag\\\\outputFineTune\"\n",
    "sequence2 = \"Hello\"\n",
    "max_len = 20\n",
    "generate_text(model2_path, sequence2, max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
